# Test Reports on the different classifications algorithms used and models created.

# SVM : Support Vector Machine 

SVM gave a significant improvement in accuracy when using best parameters calculated with GridSearchCV

84.6% -> 94.3%

Parameters:(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,
    probability=False, random_state=None, shrinking=True, tol=0.001,
    verbose=False)
    
    
# RF : Random Forest Classifier

Random Forest gave no measurable improvement in accuracy up to 14 decimal places and stagnated at 89.74358974358975 %.

Parameters : (bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=85, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=2, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=200,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False)

-> More extensive and optimized parameter selection is recommended.
-> RandomSearchCV used in rf_parkinsons_predictor_v2.py may improve performance

# ANN : Artificial Neural Network (Sequential)

ANN sequential gave an 89% accuracy with just one false negative 

Paramters are as follows:

model.add(Dense(50,activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(25, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(10, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(units=1,activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam')

model.fit(x=xtrain,y=ytrain,epochs=400,verbose=0)

Training epochs beyond 300 give no measurable change in precision



