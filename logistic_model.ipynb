{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61484555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9a6654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('vocal_data')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4186031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
       "       'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',\n",
       "       'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',\n",
       "       'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'status', 'RPDE', 'DFA',\n",
       "       'spread1', 'spread2', 'D2', 'PPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('name',inplace=True,axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabcb092",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['status']\n",
    "x = df.drop('status',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b3b6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "540beda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e4f5335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel1 = LogisticRegression()\n",
    "logmodel1.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30de117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get an error that total number of iterations was reached \n",
    "# Therefore, we attempt to scale the independent variables according to their mean and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b555d0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>MDVP:APQ</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.829300</td>\n",
       "      <td>-0.436165</td>\n",
       "      <td>-0.952037</td>\n",
       "      <td>0.334914</td>\n",
       "      <td>0.749759</td>\n",
       "      <td>0.132963</td>\n",
       "      <td>0.760800</td>\n",
       "      <td>0.131755</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.739536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332985</td>\n",
       "      <td>0.607532</td>\n",
       "      <td>-0.067893</td>\n",
       "      <td>-0.193225</td>\n",
       "      <td>-0.807838</td>\n",
       "      <td>1.760814</td>\n",
       "      <td>0.801323</td>\n",
       "      <td>0.480477</td>\n",
       "      <td>-0.210531</td>\n",
       "      <td>0.868886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.770972</td>\n",
       "      <td>-0.530974</td>\n",
       "      <td>-0.057721</td>\n",
       "      <td>0.715418</td>\n",
       "      <td>1.037674</td>\n",
       "      <td>0.453892</td>\n",
       "      <td>1.276809</td>\n",
       "      <td>0.452684</td>\n",
       "      <td>1.681731</td>\n",
       "      <td>1.768464</td>\n",
       "      <td>...</td>\n",
       "      <td>1.159454</td>\n",
       "      <td>1.548254</td>\n",
       "      <td>-0.137843</td>\n",
       "      <td>-0.634508</td>\n",
       "      <td>-0.387524</td>\n",
       "      <td>1.837562</td>\n",
       "      <td>1.479853</td>\n",
       "      <td>1.311185</td>\n",
       "      <td>0.275077</td>\n",
       "      <td>1.803605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.909476</td>\n",
       "      <td>-0.723168</td>\n",
       "      <td>-0.109875</td>\n",
       "      <td>0.884991</td>\n",
       "      <td>1.325589</td>\n",
       "      <td>0.720770</td>\n",
       "      <td>1.585687</td>\n",
       "      <td>0.721813</td>\n",
       "      <td>1.202693</td>\n",
       "      <td>1.027636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>1.175323</td>\n",
       "      <td>-0.291633</td>\n",
       "      <td>-0.279760</td>\n",
       "      <td>-0.662075</td>\n",
       "      <td>1.942048</td>\n",
       "      <td>1.141445</td>\n",
       "      <td>1.017682</td>\n",
       "      <td>-0.103629</td>\n",
       "      <td>1.402661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.909622</td>\n",
       "      <td>-0.649092</td>\n",
       "      <td>-0.114229</td>\n",
       "      <td>0.775389</td>\n",
       "      <td>1.325589</td>\n",
       "      <td>0.578885</td>\n",
       "      <td>1.284076</td>\n",
       "      <td>0.577677</td>\n",
       "      <td>1.340396</td>\n",
       "      <td>1.207698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806859</td>\n",
       "      <td>1.340229</td>\n",
       "      <td>-0.280719</td>\n",
       "      <td>-0.281346</td>\n",
       "      <td>-0.613134</td>\n",
       "      <td>1.832380</td>\n",
       "      <td>1.440945</td>\n",
       "      <td>1.293840</td>\n",
       "      <td>0.062145</td>\n",
       "      <td>1.806954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.925657</td>\n",
       "      <td>-0.606245</td>\n",
       "      <td>-0.130608</td>\n",
       "      <td>1.368893</td>\n",
       "      <td>1.901418</td>\n",
       "      <td>1.095750</td>\n",
       "      <td>2.047187</td>\n",
       "      <td>1.096793</td>\n",
       "      <td>1.836448</td>\n",
       "      <td>1.552389</td>\n",
       "      <td>...</td>\n",
       "      <td>1.216839</td>\n",
       "      <td>1.899461</td>\n",
       "      <td>-0.178026</td>\n",
       "      <td>-0.506745</td>\n",
       "      <td>-0.783021</td>\n",
       "      <td>1.909364</td>\n",
       "      <td>1.780940</td>\n",
       "      <td>0.096195</td>\n",
       "      <td>-0.130026</td>\n",
       "      <td>2.267082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
       "0    -0.829300     -0.436165     -0.952037        0.334914          0.749759   \n",
       "1    -0.770972     -0.530974     -0.057721        0.715418          1.037674   \n",
       "2    -0.909476     -0.723168     -0.109875        0.884991          1.325589   \n",
       "3    -0.909622     -0.649092     -0.114229        0.775389          1.325589   \n",
       "4    -0.925657     -0.606245     -0.130608        1.368893          1.901418   \n",
       "\n",
       "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
       "0  0.132963  0.760800    0.131755      0.745985          0.739536  ...   \n",
       "1  0.453892  1.276809    0.452684      1.681731          1.768464  ...   \n",
       "2  0.720770  1.585687    0.721813      1.202693          1.027636  ...   \n",
       "3  0.578885  1.284076    0.577677      1.340396          1.207698  ...   \n",
       "4  1.095750  2.047187    1.096793      1.836448          1.552389  ...   \n",
       "\n",
       "   MDVP:APQ  Shimmer:DDA       NHR       HNR      RPDE       DFA   spread1  \\\n",
       "0  0.332985     0.607532 -0.067893 -0.193225 -0.807838  1.760814  0.801323   \n",
       "1  1.159454     1.548254 -0.137843 -0.634508 -0.387524  1.837562  1.479853   \n",
       "2  0.699187     1.175323 -0.291633 -0.279760 -0.662075  1.942048  1.141445   \n",
       "3  0.806859     1.340229 -0.280719 -0.281346 -0.613134  1.832380  1.440945   \n",
       "4  1.216839     1.899461 -0.178026 -0.506745 -0.783021  1.909364  1.780940   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.480477 -0.210531  0.868886  \n",
       "1  1.311185  0.275077  1.803605  \n",
       "2  1.017682 -0.103629  1.402661  \n",
       "3  1.293840  0.062145  1.806954  \n",
       "4  0.096195 -0.130026  2.267082  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame(x,index=None)\n",
    "for i in a.columns:\n",
    "    mean = np.mean(a[i])\n",
    "    std = np.std(a[i])\n",
    "    a[i] = (a[i]-mean)/std\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e469ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = a.squeeze()\n",
    "y = df['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38442b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0dac234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel2 = LogisticRegression()\n",
    "logmodel2.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c45e3923",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logmodel2.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1463f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  2],\n",
       "       [ 2, 29]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "confusion_matrix(ytest,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddadfa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b894d396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70f6f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can implement a forward, backward or stepwise algorithm to determine the most important\n",
    "# indepenedent variables from the ones available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1232fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this, we make use of native packages in R language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1b8af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using R, we have calculated 3 sets of dependent variables for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15131793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward selection adds every possible variable and is thus disregarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c31e0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward and stepwise selection both include the same variables in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11a32b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
       "       'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',\n",
       "       'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',\n",
       "       'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'RPDE', 'DFA', 'spread1',\n",
       "       'spread2', 'D2', 'PPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dea8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = ['MDVP:Fo(Hz)', 'MDVP:Flo(Hz)','MDVP:Jitter(%)',\n",
    "             'MDVP:Jitter(Abs)', 'Jitter:DDP', 'MDVP:Shimmer', \n",
    "             'RPDE', 'spread1', 'spread2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fa1f268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MDVP:Fo(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)', 'MDVP:Jitter(Abs)',\n",
       "       'Jitter:DDP', 'MDVP:Shimmer', 'RPDE', 'spread1', 'spread2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_xtrain = xtrain[selection]\n",
    "selected_xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0873eea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_logmodel = LogisticRegression()\n",
    "ss_logmodel.fit(selected_xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc6de0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_xtest = xtest[selection]\n",
    "ss_predictions = ss_logmodel.predict(selected_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbdcd36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  1]\n",
      " [ 3 30]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(ss_predictions, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2546d36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71         6\n",
      "           1       0.97      0.91      0.94        33\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.80      0.87      0.83        39\n",
      "weighted avg       0.92      0.90      0.90        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ss_predictions, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e69dd09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of the subset of variables does not provide any significant increase in the accuracy\n",
    "# Therefore, a different method for reducing the number of features is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a492accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecb5ca24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16b50bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "[[ 6  2]\n",
      " [ 2 29]]\n"
     ]
    }
   ],
   "source": [
    "l_predictions = lasso_model.predict(xtest)\n",
    "print(classification_report(l_predictions, ytest))\n",
    "print(confusion_matrix(l_predictions, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "871fa818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15813281, -0.14858422, -0.15335058,  0.        , -0.22991604,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.9164597 ,  0.        , -0.16564393,\n",
       "         0.        , -0.49800225,  0.15259318,  1.3461944 ,  0.29587205,\n",
       "         0.61695768,  0.53832736]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20f67c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly, the lasso method has forced some of the co-efficients to zero\n",
    "# However, this does not result in a significant increase in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89ef0874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use recursive feature selection to decrease the number of variables in the model\n",
    "# this method selects the top n most important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43bb21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d71bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have 22 variables in total\n",
    "# We can select any number of features between 1 and 22\n",
    "# For convenience we will take the number of features between 5 and 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80db44dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 1 variables: 0.9230769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.94      0.97      0.95        31\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.90      0.86      0.88        39\n",
      "weighted avg       0.92      0.92      0.92        39\n",
      "\n",
      "Accuracy with 2 variables: 0.9230769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.94      0.97      0.95        31\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.90      0.86      0.88        39\n",
      "weighted avg       0.92      0.92      0.92        39\n",
      "\n",
      "Accuracy with 3 variables: 0.9230769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.94      0.97      0.95        31\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.90      0.86      0.88        39\n",
      "weighted avg       0.92      0.92      0.92        39\n",
      "\n",
      "Accuracy with 4 variables: 0.9230769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.94      0.97      0.95        31\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.90      0.86      0.88        39\n",
      "weighted avg       0.92      0.92      0.92        39\n",
      "\n",
      "Accuracy with 5 variables: 0.9230769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.94      0.97      0.95        31\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.90      0.86      0.88        39\n",
      "weighted avg       0.92      0.92      0.92        39\n",
      "\n",
      "Accuracy with 6 variables: 0.9230769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.94      0.97      0.95        31\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.90      0.86      0.88        39\n",
      "weighted avg       0.92      0.92      0.92        39\n",
      "\n",
      "Accuracy with 7 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 8 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 9 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 10 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 11 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 12 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 13 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 14 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 15 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 16 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 17 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 18 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 19 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 20 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 21 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n",
      "Accuracy with 22 variables: 0.8974358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         8\n",
      "           1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.84      0.84      0.84        39\n",
      "weighted avg       0.90      0.90      0.90        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for i in range(1,23):\n",
    "    rfemodel = LogisticRegression()\n",
    "    rfe = RFE(estimator = rfemodel, n_features_to_select=i)\n",
    "    rfe.fit(xtrain, ytrain)\n",
    "    \n",
    "    xtrain_rfe = rfe.transform(xtrain)\n",
    "    xtest_rfe = rfe.transform(xtest)\n",
    "    \n",
    "    rfemodel.fit(xtrain_rfe, ytrain)\n",
    "    \n",
    "    ypred = rfemodel.predict(xtest_rfe)\n",
    "    \n",
    "    accuracy = accuracy_score(ytest, ypred)\n",
    "    print('Accuracy with {} variables: {}'.format(i,accuracy))\n",
    "    results[i] = accuracy\n",
    "    print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07fe722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.9230769230769231, 2: 0.9230769230769231, 3: 0.9230769230769231, 4: 0.9230769230769231, 5: 0.9230769230769231, 6: 0.9230769230769231, 7: 0.8974358974358975, 8: 0.8974358974358975, 9: 0.8974358974358975, 10: 0.8974358974358975, 11: 0.8974358974358975, 12: 0.8974358974358975, 13: 0.8974358974358975, 14: 0.8974358974358975, 15: 0.8974358974358975, 16: 0.8974358974358975, 17: 0.8974358974358975, 18: 0.8974358974358975, 19: 0.8974358974358975, 20: 0.8974358974358975, 21: 0.8974358974358975, 22: 0.8974358974358975}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32456f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "keys = results.keys()\n",
    "values = results.values()\n",
    "plt.plot(keys, values)\n",
    "plt.xlabel('No. of features')\n",
    "plt.ylabel('Accuracy Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc730c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly, increasing the number of features included does not provide any \n",
    "# signficant improvement in accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5540d466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
